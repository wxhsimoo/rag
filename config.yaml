# RAG系统配置文件示例
# 复制此文件为 config.yaml 并根据实际情况修改配置

# 应用基础配置
app:
  name: "RAG系统"
  version: "1.0.0"

# 服务器配置
server:
  host: "0.0.0.0"
  port: 8000
  reload: true  # 开发环境自动重载
  workers: 1    # 生产环境可增加worker数量

# 日志配置（顶层）
logging:
  level: "WARNING"
  file_path: "./data/logs"
  max_file_size_mb: 100
  backup_count: 5

# 数据存储配置
storage:
  # 向量数据库配置
  vector_store:
    type: "faiss"  # faiss, chroma, pinecone

    faiss:
      dimension: 1536  # 嵌入向量维度（阿里云text-embedding-v1模型）
      index_path: "./data/vector_index"
    
  # 数据文件存储
  documents:
    type: "local"  # 本地 / 云存储 / DB

    local:
      base_path: "./data/storage"
      max_file_size_mb: 10
      documents_path: "./data"

# AI服务提供商配置
ai_providers:
  # 嵌入模型配置
  embedding:
    provider: "aliyun"  # openai, aliyun, sentence_transformers
    batch_size: 32
    max_length: 512
    
    # OpenAI嵌入配置
    openai:
      api_key: "sk-db72f231fff34184b3674ae7fa197e91"
      model: "text-embedding-ada-002"
      api_base: "https://api.openai.com/v1"
      
    # 阿里云嵌入配置
    aliyun:
      api_key: "sk-db72f231fff34184b3674ae7fa197e91"  # 请填入您的阿里云API密钥
      model: "text-embedding-v1"  # 轻量级中文支持模型
      api_base: "https://dashscope.aliyuncs.com/compatible-mode/v1"
      
    # SentenceTransformers配置
    sentence_transformers:
      model: "all-MiniLM-L6-v2"  # 或 "paraphrase-multilingual-MiniLM-L12-v2" 多语言模型
      device: "cpu"  # cpu 或 cuda
      
  # 大语言模型配置
  llm:
    provider: "aliyun"  # openai, aliyun, anthropic, local
    max_tokens: 1000
    temperature: 0.7
    
    # OpenAI配置
    openai:
      api_key: "your-openai-api-key-here"
      model: "gpt-3.5-turbo"
      api_base: "https://api.openai.com/v1"
      organization: "your-org-id"  # 可选
      
    # 阿里云LLM配置
    aliyun:
      api_key: "sk-db72f231fff34184b3674ae7fa197e91"  # 请填入您的阿里云API密钥
      model: "qwen-plus"
      api_base: "https://dashscope.aliyuncs.com/compatible-mode/v1"
      
    # Anthropic配置（如果使用Claude）
    anthropic:
      api_key: "your-anthropic-api-key-here"
      model: "claude-3-sonnet-20240229"
      
    # 本地模型配置（如果使用本地模型）
    local:
      model_path: "./models/local-llm"
      device: "cpu"  # cpu, cuda

# RAG系统配置
rag:
  # 检索配置
  retrieval:
    top_k: 5  # 检索的文档数量
    similarity_threshold: 0.7  # 相似度阈值
    max_context_length: 2000  # 最大上下文长度
    
  # 文档处理配置
  document_processing:
    chunk_size: 500  # 文档分块大小
    chunk_overlap: 50  # 分块重叠大小
    supported_formats: ["txt", "md", "json"]
    
  # 对话配置
  conversation:
    max_history_length: 10  # 最大对话历史长度
    session_timeout_minutes: 30  # 会话超时时间